{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Statistical methods for classifying mass spectrometry database search results**\n",
    "\n",
    "### **MSB72011**\n",
    "\n",
    "### **Instructor:** \n",
    "#### Mr. Sserunjogi Richard\n",
    "\n",
    "### **Authors:**\n",
    "#### 1. Aroma Emmanuel 2023/HD07/3346U\n",
    "#### 2. Mutesasira Edward 2023/HD07/3369U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Synthetic Data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to generate synthetic mass spectrometry database search results\n",
    "def generate_synthetic_results(num_samples, num_compounds):\n",
    "    X = np.random.randn(num_samples, num_compounds)  # Synthetic mass spectrometry data\n",
    "    scores = np.random.rand(num_samples, num_compounds)  # Synthetic scores/probabilities\n",
    "    return X, scores\n",
    "\n",
    "# Generate synthetic data\n",
    "num_samples = 1000\n",
    "num_compounds = 20\n",
    "X, scores = generate_synthetic_results(num_samples, num_compounds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Scores to Binary Labels;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting threshold for classification;\n",
    "threshold = 0.5\n",
    "\n",
    "# Converting scores to binary labels (incorrect: 0, correct: 1)\n",
    "y = (scores.max(axis=1) > threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensuring Both Classes are Represented;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.unique(y).size == 1:\n",
    "    # In case there's only one unique class, we can randomly flip some labels like this;\n",
    "    flip_indices = np.random.choice(len(y), size=int(0.1 * len(y)), replace=False)  # Flipping 10% of the labels\n",
    "    y[flip_indices] = 1 - y[flip_indices]  # To flip 0s to 1s and 1s to 0s\n",
    "    \n",
    "# Adding more class 0 samples;\n",
    "num_class_0_samples = int(0.4 * len(y))  # 40% of total samples\n",
    "y[:num_class_0_samples] = 0  # Assigning class 0 to the first 40% of samples\n",
    "\n",
    "# Shuffling the labels;\n",
    "np.random.shuffle(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrame and Saving to CSV;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating DataFrame for X and y;\n",
    "df = pd.DataFrame(X)\n",
    "df['target'] = y\n",
    "\n",
    "# Saving DataFrame to CSV;\n",
    "df.to_csv('synthetic_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading DataFrame from CSV;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DataFrame from CSV\n",
    "df = pd.read_csv('synthetic_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       1000 non-null   float64\n",
      " 1   1       1000 non-null   float64\n",
      " 2   2       1000 non-null   float64\n",
      " 3   3       1000 non-null   float64\n",
      " 4   4       1000 non-null   float64\n",
      " 5   5       1000 non-null   float64\n",
      " 6   6       1000 non-null   float64\n",
      " 7   7       1000 non-null   float64\n",
      " 8   8       1000 non-null   float64\n",
      " 9   9       1000 non-null   float64\n",
      " 10  10      1000 non-null   float64\n",
      " 11  11      1000 non-null   float64\n",
      " 12  12      1000 non-null   float64\n",
      " 13  13      1000 non-null   float64\n",
      " 14  14      1000 non-null   float64\n",
      " 15  15      1000 non-null   float64\n",
      " 16  16      1000 non-null   float64\n",
      " 17  17      1000 non-null   float64\n",
      " 18  18      1000 non-null   float64\n",
      " 19  19      1000 non-null   float64\n",
      " 20  target  1000 non-null   int64  \n",
      "dtypes: float64(20), int64(1)\n",
      "memory usage: 164.2 KB\n"
     ]
    }
   ],
   "source": [
    "# Printing DataFrame information;\n",
    "print(\"DataFrame information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.180551</td>\n",
       "      <td>-0.590916</td>\n",
       "      <td>0.635813</td>\n",
       "      <td>0.140767</td>\n",
       "      <td>-1.419920</td>\n",
       "      <td>-0.482936</td>\n",
       "      <td>0.480181</td>\n",
       "      <td>0.228977</td>\n",
       "      <td>0.088124</td>\n",
       "      <td>0.064522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.842790</td>\n",
       "      <td>0.184114</td>\n",
       "      <td>0.547274</td>\n",
       "      <td>0.496329</td>\n",
       "      <td>1.231079</td>\n",
       "      <td>0.125699</td>\n",
       "      <td>0.106198</td>\n",
       "      <td>0.547975</td>\n",
       "      <td>1.755091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.681506</td>\n",
       "      <td>1.090018</td>\n",
       "      <td>0.162847</td>\n",
       "      <td>1.742854</td>\n",
       "      <td>-0.159414</td>\n",
       "      <td>0.345682</td>\n",
       "      <td>-0.457797</td>\n",
       "      <td>-0.483488</td>\n",
       "      <td>0.732228</td>\n",
       "      <td>0.334868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867774</td>\n",
       "      <td>-1.194611</td>\n",
       "      <td>-0.516639</td>\n",
       "      <td>0.498988</td>\n",
       "      <td>0.622944</td>\n",
       "      <td>-0.400175</td>\n",
       "      <td>-0.219550</td>\n",
       "      <td>-0.623239</td>\n",
       "      <td>1.181455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.778645</td>\n",
       "      <td>0.308639</td>\n",
       "      <td>-1.104495</td>\n",
       "      <td>-1.054881</td>\n",
       "      <td>1.669679</td>\n",
       "      <td>-0.244908</td>\n",
       "      <td>0.546972</td>\n",
       "      <td>-2.526027</td>\n",
       "      <td>-0.334060</td>\n",
       "      <td>-0.769247</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.101024</td>\n",
       "      <td>0.170163</td>\n",
       "      <td>0.194607</td>\n",
       "      <td>0.101597</td>\n",
       "      <td>0.024509</td>\n",
       "      <td>1.086503</td>\n",
       "      <td>0.363216</td>\n",
       "      <td>0.474499</td>\n",
       "      <td>-0.617318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.443136</td>\n",
       "      <td>-0.293879</td>\n",
       "      <td>-0.838552</td>\n",
       "      <td>1.374696</td>\n",
       "      <td>-0.743341</td>\n",
       "      <td>0.108639</td>\n",
       "      <td>-0.324354</td>\n",
       "      <td>-1.173382</td>\n",
       "      <td>0.104820</td>\n",
       "      <td>-0.613695</td>\n",
       "      <td>...</td>\n",
       "      <td>2.223093</td>\n",
       "      <td>0.789754</td>\n",
       "      <td>1.068266</td>\n",
       "      <td>1.671511</td>\n",
       "      <td>-1.403007</td>\n",
       "      <td>2.013293</td>\n",
       "      <td>-1.016500</td>\n",
       "      <td>0.929351</td>\n",
       "      <td>1.000684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416401</td>\n",
       "      <td>-2.552749</td>\n",
       "      <td>-0.466438</td>\n",
       "      <td>2.497278</td>\n",
       "      <td>-1.155493</td>\n",
       "      <td>1.097357</td>\n",
       "      <td>0.697965</td>\n",
       "      <td>0.270998</td>\n",
       "      <td>0.104718</td>\n",
       "      <td>-0.897984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177377</td>\n",
       "      <td>-0.150224</td>\n",
       "      <td>1.520305</td>\n",
       "      <td>-1.248051</td>\n",
       "      <td>-0.664438</td>\n",
       "      <td>1.787128</td>\n",
       "      <td>-0.708873</td>\n",
       "      <td>-0.095383</td>\n",
       "      <td>-0.337916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.874410</td>\n",
       "      <td>-1.400708</td>\n",
       "      <td>0.239435</td>\n",
       "      <td>0.169224</td>\n",
       "      <td>2.464252</td>\n",
       "      <td>-1.178589</td>\n",
       "      <td>1.285920</td>\n",
       "      <td>-0.638513</td>\n",
       "      <td>1.235768</td>\n",
       "      <td>0.829877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.998597</td>\n",
       "      <td>0.556542</td>\n",
       "      <td>-1.128372</td>\n",
       "      <td>-0.188646</td>\n",
       "      <td>0.089196</td>\n",
       "      <td>-0.103310</td>\n",
       "      <td>0.182279</td>\n",
       "      <td>0.838761</td>\n",
       "      <td>-0.201489</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.268073</td>\n",
       "      <td>-0.185117</td>\n",
       "      <td>-0.206252</td>\n",
       "      <td>-0.480224</td>\n",
       "      <td>-0.482385</td>\n",
       "      <td>0.723632</td>\n",
       "      <td>0.089358</td>\n",
       "      <td>-1.227721</td>\n",
       "      <td>-0.277233</td>\n",
       "      <td>0.781443</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.180360</td>\n",
       "      <td>-0.018574</td>\n",
       "      <td>-0.963815</td>\n",
       "      <td>0.533911</td>\n",
       "      <td>0.679726</td>\n",
       "      <td>-0.105409</td>\n",
       "      <td>-0.574691</td>\n",
       "      <td>-0.132940</td>\n",
       "      <td>-0.199470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.054774</td>\n",
       "      <td>-0.974170</td>\n",
       "      <td>-0.044674</td>\n",
       "      <td>-0.548540</td>\n",
       "      <td>0.295761</td>\n",
       "      <td>0.799246</td>\n",
       "      <td>0.294650</td>\n",
       "      <td>1.154749</td>\n",
       "      <td>-0.328226</td>\n",
       "      <td>-0.204369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961640</td>\n",
       "      <td>0.327416</td>\n",
       "      <td>0.811634</td>\n",
       "      <td>-1.583563</td>\n",
       "      <td>-0.076668</td>\n",
       "      <td>0.949059</td>\n",
       "      <td>1.006342</td>\n",
       "      <td>-0.001859</td>\n",
       "      <td>1.399819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.101233</td>\n",
       "      <td>-1.751782</td>\n",
       "      <td>0.586891</td>\n",
       "      <td>-1.221501</td>\n",
       "      <td>0.490442</td>\n",
       "      <td>1.503872</td>\n",
       "      <td>-0.351244</td>\n",
       "      <td>-0.793609</td>\n",
       "      <td>0.043641</td>\n",
       "      <td>0.813477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232230</td>\n",
       "      <td>-0.760822</td>\n",
       "      <td>-1.417935</td>\n",
       "      <td>1.921707</td>\n",
       "      <td>-0.669319</td>\n",
       "      <td>-0.258651</td>\n",
       "      <td>-1.188035</td>\n",
       "      <td>0.631844</td>\n",
       "      <td>-1.639472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.037424</td>\n",
       "      <td>-1.723958</td>\n",
       "      <td>-1.403169</td>\n",
       "      <td>0.061580</td>\n",
       "      <td>0.958450</td>\n",
       "      <td>0.198741</td>\n",
       "      <td>-0.134427</td>\n",
       "      <td>0.330126</td>\n",
       "      <td>1.478338</td>\n",
       "      <td>0.242414</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.217302</td>\n",
       "      <td>-1.050632</td>\n",
       "      <td>-1.301196</td>\n",
       "      <td>-0.221739</td>\n",
       "      <td>0.040116</td>\n",
       "      <td>-1.678293</td>\n",
       "      <td>1.513412</td>\n",
       "      <td>-0.159294</td>\n",
       "      <td>-0.225213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.180551 -0.590916  0.635813  0.140767 -1.419920 -0.482936  0.480181   \n",
       "1  1.681506  1.090018  0.162847  1.742854 -0.159414  0.345682 -0.457797   \n",
       "2 -0.778645  0.308639 -1.104495 -1.054881  1.669679 -0.244908  0.546972   \n",
       "3  1.443136 -0.293879 -0.838552  1.374696 -0.743341  0.108639 -0.324354   \n",
       "4 -0.416401 -2.552749 -0.466438  2.497278 -1.155493  1.097357  0.697965   \n",
       "5 -0.874410 -1.400708  0.239435  0.169224  2.464252 -1.178589  1.285920   \n",
       "6 -2.268073 -0.185117 -0.206252 -0.480224 -0.482385  0.723632  0.089358   \n",
       "7 -1.054774 -0.974170 -0.044674 -0.548540  0.295761  0.799246  0.294650   \n",
       "8 -0.101233 -1.751782  0.586891 -1.221501  0.490442  1.503872 -0.351244   \n",
       "9 -0.037424 -1.723958 -1.403169  0.061580  0.958450  0.198741 -0.134427   \n",
       "\n",
       "          7         8         9  ...        11        12        13        14  \\\n",
       "0  0.228977  0.088124  0.064522  ... -0.842790  0.184114  0.547274  0.496329   \n",
       "1 -0.483488  0.732228  0.334868  ...  0.867774 -1.194611 -0.516639  0.498988   \n",
       "2 -2.526027 -0.334060 -0.769247  ... -1.101024  0.170163  0.194607  0.101597   \n",
       "3 -1.173382  0.104820 -0.613695  ...  2.223093  0.789754  1.068266  1.671511   \n",
       "4  0.270998  0.104718 -0.897984  ...  0.177377 -0.150224  1.520305 -1.248051   \n",
       "5 -0.638513  1.235768  0.829877  ... -0.998597  0.556542 -1.128372 -0.188646   \n",
       "6 -1.227721 -0.277233  0.781443  ... -1.180360 -0.018574 -0.963815  0.533911   \n",
       "7  1.154749 -0.328226 -0.204369  ...  0.961640  0.327416  0.811634 -1.583563   \n",
       "8 -0.793609  0.043641  0.813477  ...  0.232230 -0.760822 -1.417935  1.921707   \n",
       "9  0.330126  1.478338  0.242414  ... -1.217302 -1.050632 -1.301196 -0.221739   \n",
       "\n",
       "         15        16        17        18        19  target  \n",
       "0  1.231079  0.125699  0.106198  0.547975  1.755091       1  \n",
       "1  0.622944 -0.400175 -0.219550 -0.623239  1.181455       0  \n",
       "2  0.024509  1.086503  0.363216  0.474499 -0.617318       1  \n",
       "3 -1.403007  2.013293 -1.016500  0.929351  1.000684       1  \n",
       "4 -0.664438  1.787128 -0.708873 -0.095383 -0.337916       0  \n",
       "5  0.089196 -0.103310  0.182279  0.838761 -0.201489       1  \n",
       "6  0.679726 -0.105409 -0.574691 -0.132940 -0.199470       0  \n",
       "7 -0.076668  0.949059  1.006342 -0.001859  1.399819       1  \n",
       "8 -0.669319 -0.258651 -1.188035  0.631844 -1.639472       1  \n",
       "9  0.040116 -1.678293  1.513412 -0.159294 -0.225213       1  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying first 10 rows of DataFrame;\n",
    "print(\"\\nFirst 10 rows of DataFrame:\")\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data and Initializing Classifiers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Splitting the data into training and testing sets;\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # ensuring test set to be 20%\n",
    "\n",
    "# Initializing classifiers;\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating Classifiers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.34      0.38        96\n",
      "           1       0.49      0.58      0.53       104\n",
      "\n",
      "    accuracy                           0.47       200\n",
      "   macro avg       0.46      0.46      0.46       200\n",
      "weighted avg       0.46      0.47      0.46       200\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): -0.08144697841017111\n",
      "Accuracy: 0.465\n",
      "\n",
      "Support Vector Machine Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.17      0.24        96\n",
      "           1       0.52      0.82      0.63       104\n",
      "\n",
      "    accuracy                           0.51       200\n",
      "   macro avg       0.49      0.49      0.44       200\n",
      "weighted avg       0.49      0.51      0.45       200\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): -0.02107131804136713\n",
      "Accuracy: 0.505\n",
      "\n",
      "Gradient Boosting Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.32      0.37        96\n",
      "           1       0.49      0.60      0.54       104\n",
      "\n",
      "    accuracy                           0.47       200\n",
      "   macro avg       0.46      0.46      0.45       200\n",
      "weighted avg       0.46      0.47      0.46       200\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): -0.0839838508349065\n",
      "Accuracy: 0.465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, matthews_corrcoef, accuracy_score\n",
    "\n",
    "# Fitting Random Forest classifier;\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "# Predicting on the test set using Random Forest;\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# Fitting SVM classifier;\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "# Predicting on the test set using SVM;\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# Fitting Gradient Boosting classifier;\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "# Predicting on the test set using Gradient Boosting\n",
    "y_pred_gb = gb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluating classifiers;\n",
    "print(\"\\nRandom Forest Classifier:\")\n",
    "rf_report = classification_report(y_test, y_pred_rf, zero_division=1)\n",
    "rf_mcc = matthews_corrcoef(y_test, y_pred_rf)\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(rf_report)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", rf_mcc)\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "\n",
    "print(\"\\nSupport Vector Machine Classifier:\")\n",
    "svm_report = classification_report(y_test, y_pred_svm, zero_division=1)\n",
    "svm_mcc = matthews_corrcoef(y_test, y_pred_svm)\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(svm_report)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", svm_mcc)\n",
    "print(\"Accuracy:\", svm_accuracy)\n",
    "\n",
    "print(\"\\nGradient Boosting Classifier:\")\n",
    "gb_report = classification_report(y_test, y_pred_gb, zero_division=1)\n",
    "gb_mcc = matthews_corrcoef(y_test, y_pred_gb)\n",
    "gb_accuracy = accuracy_score(y_test, y_pred_gb)\n",
    "print(gb_report)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", gb_mcc)\n",
    "print(\"Accuracy:\", gb_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above:\n",
    "\n",
    "1. **Random Forest Classifier:**\n",
    "   - Precision, recall, and F1-score for both classes (0 and 1) are displayed, along with support (number of true instances) for each class.\n",
    "   - The `accuracy` for the Random Forest classifier is 0.545, indicating that it correctly predicts 54.5% of the samples.\n",
    "   - The Matthews Correlation Coefficient (MCC) is 0.097, which measures the correlation between the observed and predicted classifications. An MCC of 1 represents a perfect prediction, 0 represents no better than random prediction, and -1 represents total disagreement between prediction and observation.\n",
    "\n",
    "2. **Support Vector Machine (SVM) Classifier:**\n",
    "   - The precision, recall, and F1-score for class 0 are unusually high due to the `precision is ill-defined` warning, which occurs because there were no predictions for class 0. The `zero_division=1` parameter is used to handle this warning by setting the precision, recall, and F1-score to 1 when there are no predicted samples for a class.\n",
    "   - The accuracy for the SVM classifier is 0.49, indicating that it correctly predicts 49% of the samples.\n",
    "\n",
    "3. **Gradient Boosting Classifier:**\n",
    "   - Similar to the Random Forest Classifier, precision, recall, and F1-score for both classes are displayed, along with support for each class.\n",
    "   - The accuracy for the Gradient Boosting classifier is 0.51, indicating that it correctly predicts 51% of the samples.\n",
    "   - The Matthews Correlation Coefficient (MCC) is 0.031, which is a measure of the quality of binary classifications, indicating the correlation between the observed and predicted classifications.\n",
    "\n",
    "Overall, the Random Forest classifier has the highest accuracy among the three classifiers, followed by the Gradient Boosting classifier, while the SVM classifier performs the worst due to the issue with precision being ill-defined for class 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing hyperparameter tuning using grid search and cross-validation for the Random Forest Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier (after hyperparameter tuning):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.29      0.35        96\n",
      "           1       0.50      0.64      0.56       104\n",
      "\n",
      "    accuracy                           0.47       200\n",
      "   macro avg       0.46      0.47      0.45       200\n",
      "weighted avg       0.46      0.47      0.46       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Defining the parameter grid to search;\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initializing the Random Forest Classifier;\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Performing grid search with cross-validation;\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Getting the best parameters and the best estimator;\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Fitting the best classifier on the training data;\n",
    "best_rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set using the best classifier;\n",
    "y_pred_rf = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the best classifier;\n",
    "print(\"Random Forest Classifier (after hyperparameter tuning):\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a brief summary for the output above:\n",
    "\n",
    "---\n",
    "\n",
    "### Hyperparameter Tuning for Random Forest Classifier\n",
    "\n",
    "In this code snippet, we performed hyperparameter tuning for the Random Forest Classifier using GridSearchCV. Here's what the output means:\n",
    "\n",
    "- **Random Forest Classifier (after hyperparameter tuning):**\n",
    "  - The following results are for the Random Forest Classifier after tuning its hyperparameters.\n",
    "\n",
    "- **Precision, Recall, and F1-score:**\n",
    "  - Precision, recall, and F1-score are computed for both classes (0 and 1).\n",
    "  - Precision represents the proportion of true positive predictions among all positive predictions.\n",
    "  - Recall represents the proportion of true positive predictions among all actual positive instances.\n",
    "  - F1-score is the harmonic mean of precision and recall and provides a balance between the two metrics.\n",
    "  - For class 0: Precision is 0.55, Recall is 0.35, and F1-score is 0.43.\n",
    "  - For class 1: Precision is 0.51, Recall is 0.69, and F1-score is 0.59.\n",
    "\n",
    "- **Accuracy:**\n",
    "  - The overall accuracy of the classifier is 0.52, indicating that it correctly predicts 52% of the samples.\n",
    "\n",
    "- **Macro Average and Weighted Average:**\n",
    "  - The macro average computes the metrics independently for each class and then takes the average (unweighted) of the scores for all classes. It gives equal weight to each class.\n",
    "  - The weighted average computes the metrics for each class and then takes the weighted average based on the number of true instances for each class. It provides more weight to the majority class.\n",
    "\n",
    "Overall, the Random Forest Classifier after hyperparameter tuning achieves an accuracy of 52%, with improvements in precision, recall, and F1-score for both classes compared to the default classifier.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
